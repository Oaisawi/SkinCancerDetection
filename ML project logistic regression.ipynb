{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abf028e-558d-402b-9e9f-baca9ce5f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19020\\304710855.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Desktop\\\\ML project\\\\train-metadata.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401059 entries, 0 to 401058\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   isic_id                       401059 non-null  object \n",
      " 1   target                        401059 non-null  int64  \n",
      " 2   patient_id                    401059 non-null  object \n",
      " 3   age_approx                    398261 non-null  float64\n",
      " 4   sex                           389542 non-null  object \n",
      " 5   anatom_site_general           395303 non-null  object \n",
      " 6   clin_size_long_diam_mm        401059 non-null  float64\n",
      " 7   image_type                    401059 non-null  object \n",
      " 8   tbp_tile_type                 401059 non-null  object \n",
      " 9   tbp_lv_A                      401059 non-null  float64\n",
      " 10  tbp_lv_Aext                   401059 non-null  float64\n",
      " 11  tbp_lv_B                      401059 non-null  float64\n",
      " 12  tbp_lv_Bext                   401059 non-null  float64\n",
      " 13  tbp_lv_C                      401059 non-null  float64\n",
      " 14  tbp_lv_Cext                   401059 non-null  float64\n",
      " 15  tbp_lv_H                      401059 non-null  float64\n",
      " 16  tbp_lv_Hext                   401059 non-null  float64\n",
      " 17  tbp_lv_L                      401059 non-null  float64\n",
      " 18  tbp_lv_Lext                   401059 non-null  float64\n",
      " 19  tbp_lv_areaMM2                401059 non-null  float64\n",
      " 20  tbp_lv_area_perim_ratio       401059 non-null  float64\n",
      " 21  tbp_lv_color_std_mean         401059 non-null  float64\n",
      " 22  tbp_lv_deltaA                 401059 non-null  float64\n",
      " 23  tbp_lv_deltaB                 401059 non-null  float64\n",
      " 24  tbp_lv_deltaL                 401059 non-null  float64\n",
      " 25  tbp_lv_deltaLB                401059 non-null  float64\n",
      " 26  tbp_lv_deltaLBnorm            401059 non-null  float64\n",
      " 27  tbp_lv_eccentricity           401059 non-null  float64\n",
      " 28  tbp_lv_location               401059 non-null  object \n",
      " 29  tbp_lv_location_simple        401059 non-null  object \n",
      " 30  tbp_lv_minorAxisMM            401059 non-null  float64\n",
      " 31  tbp_lv_nevi_confidence        401059 non-null  float64\n",
      " 32  tbp_lv_norm_border            401059 non-null  float64\n",
      " 33  tbp_lv_norm_color             401059 non-null  float64\n",
      " 34  tbp_lv_perimeterMM            401059 non-null  float64\n",
      " 35  tbp_lv_radial_color_std_max   401059 non-null  float64\n",
      " 36  tbp_lv_stdL                   401059 non-null  float64\n",
      " 37  tbp_lv_stdLExt                401059 non-null  float64\n",
      " 38  tbp_lv_symm_2axis             401059 non-null  float64\n",
      " 39  tbp_lv_symm_2axis_angle       401059 non-null  int64  \n",
      " 40  tbp_lv_x                      401059 non-null  float64\n",
      " 41  tbp_lv_y                      401059 non-null  float64\n",
      " 42  tbp_lv_z                      401059 non-null  float64\n",
      " 43  attribution                   401059 non-null  object \n",
      " 44  copyright_license             401059 non-null  object \n",
      " 45  lesion_id                     22058 non-null   object \n",
      " 46  iddx_full                     401059 non-null  object \n",
      " 47  iddx_1                        401059 non-null  object \n",
      " 48  iddx_2                        1068 non-null    object \n",
      " 49  iddx_3                        1065 non-null    object \n",
      " 50  iddx_4                        551 non-null     object \n",
      " 51  iddx_5                        1 non-null       object \n",
      " 52  mel_mitotic_index             53 non-null      object \n",
      " 53  mel_thick_mm                  63 non-null      float64\n",
      " 54  tbp_lv_dnn_lesion_confidence  401059 non-null  float64\n",
      "dtypes: float64(35), int64(2), object(18)\n",
      "memory usage: 168.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Desktop\\\\ML project\\\\train-metadata.csv\")\n",
    "\n",
    "# Display  information\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8269643f-edbc-47a6-a075-372c259c4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19020\\3657371128.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop empty columns\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# Fill missing values in numerical columns with mean or median\n",
    "for col in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a7f218-5dc5-44d4-8b60-fa0947c12933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply label encoding to each non-numeric column\n",
    "label_encoder = LabelEncoder()\n",
    "for col in non_numeric_columns:\n",
    "    data[col] = label_encoder.fit_transform(data[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e066d1eb-f48d-4410-8a9d-430bf5318aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 50,000 rows\n",
    "sample_data = data.sample(50000, random_state=42)\n",
    "\n",
    "# Separate features and target\n",
    "X_sample = sample_data.drop(columns=['target'])\n",
    "y_sample = sample_data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00b2a75-e56e-42d5-86fd-a8232d6bf056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9987\n",
      "           1       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       0.96      0.92      0.94     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9986    1]\n",
      " [   2   11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deef46a8-c88a-4b3e-bd2c-597f3e69e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9987\n",
      "           1       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      0.92      0.96     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Confusion Matrix after SMOTE:\n",
      "[[9987    0]\n",
      " [   2   11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train logistic regression on the resampled dataset\n",
    "logreg_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate again\n",
    "print(\"Classification Report after SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix after SMOTE:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e139068d-ec7b-4a5f-b82f-d5ae90555488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Coefficient\n",
      "45           iddx_full     3.630441\n",
      "2           age_approx     0.564434\n",
      "8             tbp_lv_A     0.272610\n",
      "46              iddx_1     0.199815\n",
      "9          tbp_lv_Aext     0.182206\n",
      "25  tbp_lv_deltaLBnorm     0.152760\n",
      "24      tbp_lv_deltaLB     0.126410\n",
      "35         tbp_lv_stdL     0.116003\n",
      "21       tbp_lv_deltaA     0.090403\n",
      "41            tbp_lv_z     0.085535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': logreg_model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))  # Top 10 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc3d2f80-bcad-4e9e-95ab-e5c42dc0f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for coefficient importance\n",
    "threshold = 0.1\n",
    "\n",
    "# Filter features with coefficients above the threshold\n",
    "important_features = feature_importance[feature_importance['Coefficient'].abs() > threshold]\n",
    "\n",
    "# Select only these features in the dataset\n",
    "X_train_filtered = X_train[important_features['Feature']]\n",
    "X_test_filtered = X_test[important_features['Feature']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53d77280-2035-427e-b6b5-52febc4ceeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Filtered Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9987\n",
      "           1       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       0.96      1.00      0.98     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Confusion Matrix with Filtered Features:\n",
      "[[9986    1]\n",
      " [   0   13]]\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression with filtered features\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "logreg_model.fit(X_train_filtered, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_filtered = logreg_model.predict(X_test_filtered)\n",
    "print(\"Classification Report with Filtered Features:\")\n",
    "print(classification_report(y_test, y_pred_filtered))\n",
    "print(\"Confusion Matrix with Filtered Features:\")\n",
    "print(confusion_matrix(y_test, y_pred_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f469ab0c-dbef-4bf5-b953-4b53426336e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.97056321 0.94994995 0.93470752 0.89987484 0.93470752]\n",
      "Mean F1 Score: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(logreg_model, X_sample, y_sample, cv=5, scoring='f1_macro')\n",
    "print(f\"Cross-Validation F1 Scores: {cv_scores}\")\n",
    "print(f\"Mean F1 Score: {cv_scores.mean():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
